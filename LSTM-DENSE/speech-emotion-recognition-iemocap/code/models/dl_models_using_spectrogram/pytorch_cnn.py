# -*- coding: utf-8 -*-
"""PyTorch_CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MlJ-bxvO-W0sQxc2Y1uDpuIKN_USOLmt
"""

from __future__ import print_function
import numpy as np 
import pandas as pd 
import argparse
import pickle
import random
import matplotlib.pyplot as plt
import seaborn as sns
import IPython.display as ipd
import warnings
import os
warnings.filterwarnings('ignore')
from sklearn.metrics import confusion_matrix
import wandb

import torch 
import torch.nn.functional as F
from torchvision import transforms, models, datasets
from torch.autograd import Variable
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import confusion_matrix, classification_report
import librosa
import librosa.display
import regex as re
from torchvision.io import read_image
import torch.nn as nn


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Device being used is {}'.format(device))


classes = {'angry':0, 'happiness':1, 'excited':2, 'neutral':3} 

class CustomDataset(Dataset):
    def __init__(self, dataset_path, split, val_session, transform):
        #breakpoint()
        self.transform = transform
        emotion_dirs = os.listdir(dataset_path)
        self.spectrogram = []
        self.labels = []
        for emotion_dir in emotion_dirs:
            for image in os.listdir(os.path.join(dataset_path, emotion_dir)):
                #if extension not is not .jpg, skip
                if image.split('.')[-1] != 'jpg':
                    continue
                image_session = image.split('_')[0]
                image_session = int(re.search(r'\d+', image_session).group(0))
                if split == 'train':
                    if image_session != val_session:
                        #breakpoint()
                        self.spectrogram.append(os.path.join(dataset_path, emotion_dir, image))
                        self.labels.append(classes[emotion_dir])
                else:
                    if image_session == val_session:
                        self.spectrogram.append(os.path.join(dataset_path, emotion_dir, image))
                        self.labels.append(classes[emotion_dir])
        

    def __len__(self):
        return len(self.spectrogram)

    def __getitem__(self, idx):
        #breakpoint()
        return self.transform(read_image(self.spectrogram[idx])), torch.tensor(self.labels[idx])



def load_data(args, validation_session=5, batch_size=64):
    #dataset = pickle.load(open((args.data_dir+'feature_vectors.pkl'), 'rb'))
    #filter the dataset with label values between 0 and 3
    dataset_path = args.data_dir
    #input image is stored as tensor
    train_transforms = transforms.Compose([transforms.ToPILImage(),
                                       transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                                       ])
    
    val_transforms = transforms.Compose([transforms.ToPILImage(),
                                   transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
                                   ])
    dataset = CustomDataset(dataset_path, 'train', validation_session, train_transforms)
    val_dataset = CustomDataset(dataset_path, 'val', validation_session, val_transforms)
    print('dataset ',dataset.__len__())

    trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
    valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)

    for i, (inputs, labels) in enumerate(trainloader):
        print(inputs.shape)
        print(labels)
        print('dataloader is working')
        break
    #print('Training batches are {} and examples are {}'.format(len(trainloader), len(trainloader.dataset)))
    #print('Validation batches are {} and examples are {}'.format(len(valloader), len(valloader.dataset)))
    return trainloader, valloader

def train(epoch, model, trainloader, criterion, optimizer ):
    model.train()
    correct_train = 0
    train_loss = 0
    train_acc = 0
    
    for batch_idx, (data, target) in enumerate(trainloader):
        data, target = data.to(device), target.to(device)
        print(data.shape)
        
        # zero the gradient, forward, backward and running pytorch rhythm
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
        # get the label of prediction
        pred = torch.max(output.data, 1)[1]
        correct_train += pred.eq(target.data.view_as(pred)).cpu().sum()
        
        if batch_idx % 10 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\n'.format(
                epoch, batch_idx * len(data), len(trainloader.dataset),
                100. * batch_idx / len(trainloader), loss.item()))
    
    train_loss /= len(trainloader.dataset)
    train_acc = 100. * correct_train / len(trainloader.dataset)
    print('\nTrain set: Average loss: {:.4f}\n'.format(train_loss))
    print('\nTrain Accuracy: {}/{} ({:.0f}%)\n'.format(
        correct_train, len(trainloader.dataset), 100. * correct_train / len(trainloader.dataset)))
    
    return train_loss, int(train_acc.numpy())


def test(model, valloader, criterion):
    model.eval()
    test_loss = 0
    test_acc = 0
    correct = 0
    history_test = []

    pred_model = []
    actual = []

    for data, target in valloader:
        data, target = data.to(device), target.to(device)

        # output from model
        output = model(data)

        # sum total loss
        test_loss += criterion(output, target).item()

        # get the label of prediction
        pred = torch.max(output.data, 1)[1]
        correct += pred.eq(target.data.view_as(pred)).cpu().sum()

        pred_model.append(pred.cpu().numpy())
        actual.append(target.data.cpu().numpy())


    test_loss /= len(valloader.dataset)
    test_acc = 100. * correct / len(valloader.dataset)
    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(valloader.dataset),
        100. * correct / len(valloader.dataset)))


    #pred_with_label = [label_to_class[label] for label in list(np.concatenate(pred_model))]
    #actual_with_label = [label_to_class[label] for label in list(np.concatenate(actual))]

    #confusion_matrix(actual_with_label, pred_with_label, labels=final_labels)

    #print('\n Classification Report \n {} \n'.format(classification_report(actual_with_label, pred_with_label)))

    return test_loss, int(test_acc.numpy())
            





class Crude_Diag(nn.Module):
    def __init__(self, in_features):
        super(Crude_Diag, self).__init__()
        
        # Set a fixed seed for reproducibility
        torch.manual_seed(0)
        
        # Initialize scaling factors and weight matrix
        scaling_factors = torch.rand(in_features)
        weight = torch.diag(scaling_factors)
        
        # Modify weight matrix to set non-diagonal elements to zero
        with torch.no_grad():
            for i in range(in_features):
                for j in range(in_features):
                    if i != j:
                        weight[i, j] = 0.0
                        weight[i, j].requires_grad = False
        
        # Define linear layer with diagonal weight matrix
        self.linear = nn.Linear(in_features, in_features, bias=False)
        self.linear.weight = nn.Parameter(weight)
        
    def forward(self, x):
        x = self.linear(x)
        return x

class CNN(torch.nn.Module):

    def __init__(self):
        super(CNN, self).__init__()
        # L1 ImgIn shape=(?, 224, 224, 3)
        #    Conv     -> (?, 224, 224, 16)
        #    Pool     -> (?, 112, 112, 16)
        keep_prob = 0.5
        self.layer1 = torch.nn.Sequential(
            torch.nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=1 - keep_prob))
        # L2 ImgIn shape=(?, 112, 112, 16)
        #    Conv      ->(?, 112, 112, 32)
        #    Pool      ->(?, 56, 56, 32)
        self.layer2 = torch.nn.Sequential(
            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=1 - keep_prob))
        # L3 ImgIn shape=(?, 56, 56, 32)
        #    Conv      ->(?, 56, 56, 64)
        #    Pool      ->(?, 28, 28, 64)
        self.layer3 = torch.nn.Sequential(
            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=1 - keep_prob))
        
        # L4 ImgIn shape=(?, 28, 28, 64)
        #    Conv      ->(?, 28, 28, 16)
        #    Pool      ->(?, 14, 14, 16)
        self.layer4 = torch.nn.Sequential(
            torch.nn.Conv2d(64, 16, kernel_size=1, stride=1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2, stride=2),
            torch.nn.Dropout(p=1 - keep_prob))

        # L4 FC 14x14x16 inputs -> 512 outputs
        self.fc1 = torch.nn.Linear(14 * 14 * 16, 512, bias=True)
        torch.nn.init.xavier_uniform(self.fc1.weight)
#         self.layer4 = torch.nn.Sequential(
#             self.fc1,
#             torch.nn.ReLU(),
#             torch.nn.Dropout(p=1 - keep_prob))
        # L5 Final FC 1024 inputs -> 512 outputs
        
        # Affine Layer
        self.Diag_Affine = Crude_Diag(512)
        self.test_linear = torch.nn.Linear(512,512)
        self.fc2 = torch.nn.Linear(512, 4, bias=True)
        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters
        # L6 Final FC 512 inputs -> 4 outputs
#         self.fc3 = torch.nn.Linear(512, 4, bias=True)
#         torch.nn.init.xavier_uniform_(self.fc3.weight) # initialize parameters

        self.dropout = nn.Dropout(p=0.3)

    def forward(self, x):
        #x= x.reshape(x.shape[0],1,x.shape[1],x.shape[2])
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
#         print(out.size())
        out = out.view(out.size(0), -1)
#         print(out.size())# Flatten them for FC
        out = self.fc1(out)
        out = self.dropout(out)
        out = self.Diag_Affine(out)
        # out = self.test_linear(out)
        out = self.fc2(out)
#         out = self.fc3(out)
        return out
    

        
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad) 
    

def main(args):
    
    for val_ses in range(1, 6):

        config = {
            "learning_rate": 0.001,
            "batch_size": 64,
            "epochs": 100,
            "architecture": "CNN",
        } 
        
        trainloader, valloader = load_data(args, val_ses, config['batch_size'])
        print('Validation session is {}'.format(val_ses))
        print('Training batches are {} and examples are {}'.format(len(trainloader), len(trainloader.dataset)))
        print('Validation batches are {} and examples are {}'.format(len(valloader), len(valloader.dataset)))

        model = CNN()
        model.to(device)

    

        print("network before turning off sparse layer", count_parameters(model))

        for param in model.Diag_Affine.parameters():
            param.requires_grad = False     
        print("network after turning off sparse layer", count_parameters(model))




        #print(trainloader.dataset.class_to_idx)
        anger = 0
        happiness = 0
        neutral = 0
        sadnes = 0
        for i, (inputs, labels) in enumerate(trainloader):
            labels = list(labels.numpy())
            anger += labels.count(0)
            happiness += labels.count(1)
            neutral += labels.count(2)
            sadnes += labels.count(3)
        for i, (inputs, labels) in enumerate(valloader):
            labels = list(labels.numpy())
            anger += labels.count(0)
            happiness += labels.count(1)
            neutral += labels.count(2)
            sadnes += labels.count(3)

        print('Anger: {}, Happiness: {}, Neutral: {}, Sadness: {}'.format(anger, happiness, neutral, sadnes))
        sample_weights = [1/anger, 1/happiness, 1/neutral, 1/sadnes]
        class_weights = torch.FloatTensor(sample_weights).cuda()

        criterion = nn.CrossEntropyLoss(weight=class_weights)
        optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

        wandb.login(key="a94b61c6268e685bc180a0634fae8dc030cd8ed4") #API Key is in your wandb account, under settings (wandb.ai/settings)
        
        # Create your wandb run
        run = wandb.init(
            name    = "initial_run_validation_session_{}".format(val_ses), ### Wandb creates random run names if you skip this field, we recommend you give useful names
            reinit  = True, ### Allows reinitalizing runs when you re-run this cell
            project = "IDL_Project", ### Project should be created in your wandb account 
            config  = config, ### Wandb Config for your run
            entity="sgowrira"
        )

        history, n_epoch = [], config["epochs"]
        best_val_acc = 0
        
        for epoch in range(1, n_epoch):    
            # exp_lr_scheduler.step(epoch)
            # import pdb
            # pdb.set_trace()
            train_loss, train_acc = train(epoch, model, trainloader, criterion, optimizer)
            test_loss, test_acc = test(model, valloader, criterion)
            wandb.log({"train_loss": train_loss, "train_acc": train_acc, "test_loss": test_loss, "test_acc": test_acc})
            if test_acc > best_val_acc:
                best_val_acc = test_acc
                torch.save(model.state_dict(), 'best_model_session_{}.pt'.format(val_ses))


            
            # plateau_scheduler.step(test_loss)
            history.append([train_loss, train_acc, test_loss, test_acc])

        run.finish()

        history_df = pd.DataFrame(history, columns=["train_loss", "train_acc", "test_loss", "test_acc"])
        history_df["epoch"] = [x for x in range(1, n_epoch)]
        print(history_df)
 
    

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, default='/home/sgowrira/domain_adaptation/LSTM-DENSE/speech-emotion-recognition-iemocap/preprocess_info/images/', help='path to dataset')
    args = parser.parse_args()
    main(args)
    



