{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_features = pd.read_csv('/home/arpitsah/Desktop/Projects Fall-22/DA/domain_adaptation/LSTM-DENSE/speech-emotion-recognition-iemocap/preprocess_info/audio_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>label</th>\n",
       "      <th>flatness</th>\n",
       "      <th>zerocr</th>\n",
       "      <th>meancent</th>\n",
       "      <th>stdcent</th>\n",
       "      <th>maxcent</th>\n",
       "      <th>pitchmean</th>\n",
       "      <th>pitchmax</th>\n",
       "      <th>pitchmin</th>\n",
       "      <th>...</th>\n",
       "      <th>mel126</th>\n",
       "      <th>mel127</th>\n",
       "      <th>mel128</th>\n",
       "      <th>contrast1</th>\n",
       "      <th>contrast2</th>\n",
       "      <th>contrast3</th>\n",
       "      <th>contrast4</th>\n",
       "      <th>contrast5</th>\n",
       "      <th>contrast6</th>\n",
       "      <th>contrast7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01M_script01_2_F000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.055343</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.014044</td>\n",
       "      <td>36.543182</td>\n",
       "      <td>177.455444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.308270e-10</td>\n",
       "      <td>1.263389e-10</td>\n",
       "      <td>1.235865e-10</td>\n",
       "      <td>17.239212</td>\n",
       "      <td>13.941932</td>\n",
       "      <td>14.874545</td>\n",
       "      <td>14.849185</td>\n",
       "      <td>16.230488</td>\n",
       "      <td>17.757777</td>\n",
       "      <td>57.287688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01M_script01_2_F001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>68.735916</td>\n",
       "      <td>155.426529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.936848e-11</td>\n",
       "      <td>2.863149e-11</td>\n",
       "      <td>2.817110e-11</td>\n",
       "      <td>16.649447</td>\n",
       "      <td>12.375123</td>\n",
       "      <td>14.778021</td>\n",
       "      <td>14.914547</td>\n",
       "      <td>16.769379</td>\n",
       "      <td>16.838275</td>\n",
       "      <td>58.822633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ses01M_script01_2_F002</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.060826</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.016922</td>\n",
       "      <td>80.757545</td>\n",
       "      <td>274.377533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500557e-10</td>\n",
       "      <td>1.469233e-10</td>\n",
       "      <td>1.449430e-10</td>\n",
       "      <td>15.968722</td>\n",
       "      <td>13.303472</td>\n",
       "      <td>15.370515</td>\n",
       "      <td>14.653921</td>\n",
       "      <td>17.685535</td>\n",
       "      <td>16.651051</td>\n",
       "      <td>58.517737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ses01M_script01_2_F003</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.066547</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>46.886211</td>\n",
       "      <td>177.291580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.028152e-09</td>\n",
       "      <td>1.012797e-09</td>\n",
       "      <td>1.002813e-09</td>\n",
       "      <td>15.986299</td>\n",
       "      <td>12.234666</td>\n",
       "      <td>14.501920</td>\n",
       "      <td>14.767501</td>\n",
       "      <td>16.860734</td>\n",
       "      <td>17.900835</td>\n",
       "      <td>57.929539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01M_script01_2_F004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>10.885402</td>\n",
       "      <td>102.002754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.732974e-11</td>\n",
       "      <td>2.673165e-11</td>\n",
       "      <td>2.635169e-11</td>\n",
       "      <td>17.397841</td>\n",
       "      <td>14.855312</td>\n",
       "      <td>16.196001</td>\n",
       "      <td>16.824510</td>\n",
       "      <td>17.497636</td>\n",
       "      <td>19.738831</td>\n",
       "      <td>55.205751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wav_file  label  flatness    zerocr  meancent   stdcent  \\\n",
       "0  Ses01M_script01_2_F000      0  0.000240  0.055343  0.008130  0.001714   \n",
       "1  Ses01M_script01_2_F001      0  0.000177  0.049172  0.005102  0.001404   \n",
       "2  Ses01M_script01_2_F002      8  0.000250  0.060826  0.008547  0.001922   \n",
       "3  Ses01M_script01_2_F003      8  0.000221  0.066547  0.008475  0.002963   \n",
       "4  Ses01M_script01_2_F004      0  0.000159  0.071784  0.006579  0.001990   \n",
       "\n",
       "    maxcent  pitchmean    pitchmax  pitchmin  ...        mel126        mel127  \\\n",
       "0  0.014044  36.543182  177.455444       0.0  ...  1.308270e-10  1.263389e-10   \n",
       "1  0.012810  68.735916  155.426529       0.0  ...  2.936848e-11  2.863149e-11   \n",
       "2  0.016922  80.757545  274.377533       0.0  ...  1.500557e-10  1.469233e-10   \n",
       "3  0.024325  46.886211  177.291580       0.0  ...  1.028152e-09  1.012797e-09   \n",
       "4  0.017874  10.885402  102.002754       0.0  ...  2.732974e-11  2.673165e-11   \n",
       "\n",
       "         mel128  contrast1  contrast2  contrast3  contrast4  contrast5  \\\n",
       "0  1.235865e-10  17.239212  13.941932  14.874545  14.849185  16.230488   \n",
       "1  2.817110e-11  16.649447  12.375123  14.778021  14.914547  16.769379   \n",
       "2  1.449430e-10  15.968722  13.303472  15.370515  14.653921  17.685535   \n",
       "3  1.002813e-09  15.986299  12.234666  14.501920  14.767501  16.860734   \n",
       "4  2.635169e-11  17.397841  14.855312  16.196001  16.824510  17.497636   \n",
       "\n",
       "   contrast6  contrast7  \n",
       "0  17.757777  57.287688  \n",
       "1  16.838275  58.822633  \n",
       "2  16.651051  58.517737  \n",
       "3  17.900835  57.929539  \n",
       "4  19.738831  55.205751  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emotion_dict = {'ang': 0,\n",
    "                'hap': 1,\n",
    "                'exc': 2,\n",
    "                'sad': 3,\n",
    "                'fru': 4,\n",
    "                'fea': 5,\n",
    "                'sur': 6,\n",
    "                'neu': 7,\n",
    "                'xxx': 8,\n",
    "                'oth': 8,\n",
    "                'dis': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8    2026\n",
       "4    1473\n",
       "7    1329\n",
       "0     936\n",
       "3     869\n",
       "2     806\n",
       "1     454\n",
       "6      91\n",
       "5      30\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_features.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_4emotions = audio_features[audio_features[\"label\"].isin([0, 1, 3, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3588, 201)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_4emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emotion(x):\n",
    "    if x == 0:\n",
    "        return \"angry\"\n",
    "    elif x == 1:\n",
    "        return \"happy\"\n",
    "    elif x == 3:\n",
    "        return \"sadness\"\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_4emotions[\"emotion\"] = audio_4emotions[\"label\"].apply(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_new(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x == 1:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_4emotions[\"label\"] = audio_4emotions[\"label\"].apply(label_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1329\n",
       "0     936\n",
       "2     869\n",
       "1     454\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_4emotions[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_file</th>\n",
       "      <th>label</th>\n",
       "      <th>flatness</th>\n",
       "      <th>zerocr</th>\n",
       "      <th>meancent</th>\n",
       "      <th>stdcent</th>\n",
       "      <th>maxcent</th>\n",
       "      <th>pitchmean</th>\n",
       "      <th>pitchmax</th>\n",
       "      <th>pitchmin</th>\n",
       "      <th>...</th>\n",
       "      <th>mel127</th>\n",
       "      <th>mel128</th>\n",
       "      <th>contrast1</th>\n",
       "      <th>contrast2</th>\n",
       "      <th>contrast3</th>\n",
       "      <th>contrast4</th>\n",
       "      <th>contrast5</th>\n",
       "      <th>contrast6</th>\n",
       "      <th>contrast7</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ses01M_script01_2_F000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.055343</td>\n",
       "      <td>0.008130</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.014044</td>\n",
       "      <td>36.543182</td>\n",
       "      <td>177.455444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.263389e-10</td>\n",
       "      <td>1.235865e-10</td>\n",
       "      <td>17.239212</td>\n",
       "      <td>13.941932</td>\n",
       "      <td>14.874545</td>\n",
       "      <td>14.849185</td>\n",
       "      <td>16.230488</td>\n",
       "      <td>17.757777</td>\n",
       "      <td>57.287688</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ses01M_script01_2_F001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.049172</td>\n",
       "      <td>0.005102</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.012810</td>\n",
       "      <td>68.735916</td>\n",
       "      <td>155.426529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.863149e-11</td>\n",
       "      <td>2.817110e-11</td>\n",
       "      <td>16.649447</td>\n",
       "      <td>12.375123</td>\n",
       "      <td>14.778021</td>\n",
       "      <td>14.914547</td>\n",
       "      <td>16.769379</td>\n",
       "      <td>16.838275</td>\n",
       "      <td>58.822633</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ses01M_script01_2_F004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>10.885402</td>\n",
       "      <td>102.002754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.673165e-11</td>\n",
       "      <td>2.635169e-11</td>\n",
       "      <td>17.397841</td>\n",
       "      <td>14.855312</td>\n",
       "      <td>16.196001</td>\n",
       "      <td>16.824510</td>\n",
       "      <td>17.497636</td>\n",
       "      <td>19.738831</td>\n",
       "      <td>55.205751</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ses01M_script01_2_F005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.098830</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>15.153377</td>\n",
       "      <td>101.897003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.131963e-08</td>\n",
       "      <td>1.111381e-08</td>\n",
       "      <td>14.318142</td>\n",
       "      <td>16.569613</td>\n",
       "      <td>19.012398</td>\n",
       "      <td>16.803689</td>\n",
       "      <td>18.371521</td>\n",
       "      <td>19.161257</td>\n",
       "      <td>58.707505</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ses01M_script01_2_F009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.071346</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>8.757346</td>\n",
       "      <td>134.542175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.125818e-11</td>\n",
       "      <td>1.116775e-11</td>\n",
       "      <td>16.525942</td>\n",
       "      <td>15.347263</td>\n",
       "      <td>16.921631</td>\n",
       "      <td>15.839474</td>\n",
       "      <td>17.357330</td>\n",
       "      <td>18.459367</td>\n",
       "      <td>52.495735</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 wav_file  label  flatness    zerocr  meancent   stdcent  \\\n",
       "0  Ses01M_script01_2_F000      0  0.000240  0.055343  0.008130  0.001714   \n",
       "1  Ses01M_script01_2_F001      0  0.000177  0.049172  0.005102  0.001404   \n",
       "4  Ses01M_script01_2_F004      0  0.000159  0.071784  0.006579  0.001990   \n",
       "5  Ses01M_script01_2_F005      0  0.000197  0.098830  0.002747  0.000960   \n",
       "9  Ses01M_script01_2_F009      0  0.000130  0.071346  0.001704  0.000633   \n",
       "\n",
       "    maxcent  pitchmean    pitchmax  pitchmin  ...        mel127        mel128  \\\n",
       "0  0.014044  36.543182  177.455444       0.0  ...  1.263389e-10  1.235865e-10   \n",
       "1  0.012810  68.735916  155.426529       0.0  ...  2.863149e-11  2.817110e-11   \n",
       "4  0.017874  10.885402  102.002754       0.0  ...  2.673165e-11  2.635169e-11   \n",
       "5  0.007159  15.153377  101.897003       0.0  ...  1.131963e-08  1.111381e-08   \n",
       "9  0.004604   8.757346  134.542175       0.0  ...  1.125818e-11  1.116775e-11   \n",
       "\n",
       "   contrast1  contrast2  contrast3  contrast4  contrast5  contrast6  \\\n",
       "0  17.239212  13.941932  14.874545  14.849185  16.230488  17.757777   \n",
       "1  16.649447  12.375123  14.778021  14.914547  16.769379  16.838275   \n",
       "4  17.397841  14.855312  16.196001  16.824510  17.497636  19.738831   \n",
       "5  14.318142  16.569613  19.012398  16.803689  18.371521  19.161257   \n",
       "9  16.525942  15.347263  16.921631  15.839474  17.357330  18.459367   \n",
       "\n",
       "   contrast7  emotion  \n",
       "0  57.287688    angry  \n",
       "1  58.822633    angry  \n",
       "4  55.205751    angry  \n",
       "5  58.707505    angry  \n",
       "9  52.495735    angry  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_4emotions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_4emotions.columns.get_loc(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw = audio_4emotions.iloc[:, 2:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flatness</th>\n",
       "      <th>zerocr</th>\n",
       "      <th>meancent</th>\n",
       "      <th>stdcent</th>\n",
       "      <th>maxcent</th>\n",
       "      <th>pitchmean</th>\n",
       "      <th>pitchmax</th>\n",
       "      <th>pitchmin</th>\n",
       "      <th>pitchstd</th>\n",
       "      <th>pitch_tuning_offset</th>\n",
       "      <th>...</th>\n",
       "      <th>mel126</th>\n",
       "      <th>mel127</th>\n",
       "      <th>mel128</th>\n",
       "      <th>contrast1</th>\n",
       "      <th>contrast2</th>\n",
       "      <th>contrast3</th>\n",
       "      <th>contrast4</th>\n",
       "      <th>contrast5</th>\n",
       "      <th>contrast6</th>\n",
       "      <th>contrast7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115663</td>\n",
       "      <td>0.162883</td>\n",
       "      <td>0.240805</td>\n",
       "      <td>0.096425</td>\n",
       "      <td>0.182149</td>\n",
       "      <td>0.211254</td>\n",
       "      <td>0.439522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372568</td>\n",
       "      <td>0.404040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836009e-06</td>\n",
       "      <td>1.811076e-06</td>\n",
       "      <td>1.795984e-06</td>\n",
       "      <td>0.512331</td>\n",
       "      <td>0.301199</td>\n",
       "      <td>0.207383</td>\n",
       "      <td>0.211420</td>\n",
       "      <td>0.214275</td>\n",
       "      <td>0.210560</td>\n",
       "      <td>0.539301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080613</td>\n",
       "      <td>0.127624</td>\n",
       "      <td>0.141372</td>\n",
       "      <td>0.075476</td>\n",
       "      <td>0.163086</td>\n",
       "      <td>0.397358</td>\n",
       "      <td>0.384960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393772</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>...</td>\n",
       "      <td>4.120602e-07</td>\n",
       "      <td>4.103606e-07</td>\n",
       "      <td>4.093246e-07</td>\n",
       "      <td>0.460097</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.198829</td>\n",
       "      <td>0.218364</td>\n",
       "      <td>0.296429</td>\n",
       "      <td>0.123045</td>\n",
       "      <td>0.626767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.070928</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>0.189870</td>\n",
       "      <td>0.115045</td>\n",
       "      <td>0.241298</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>0.252640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161979</td>\n",
       "      <td>0.191919</td>\n",
       "      <td>...</td>\n",
       "      <td>3.834468e-07</td>\n",
       "      <td>3.831249e-07</td>\n",
       "      <td>3.828833e-07</td>\n",
       "      <td>0.526381</td>\n",
       "      <td>0.382648</td>\n",
       "      <td>0.324490</td>\n",
       "      <td>0.421281</td>\n",
       "      <td>0.407452</td>\n",
       "      <td>0.399111</td>\n",
       "      <td>0.420664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.092065</td>\n",
       "      <td>0.411366</td>\n",
       "      <td>0.064047</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.075815</td>\n",
       "      <td>0.087601</td>\n",
       "      <td>0.252379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185685</td>\n",
       "      <td>0.808081</td>\n",
       "      <td>...</td>\n",
       "      <td>1.635418e-04</td>\n",
       "      <td>1.622759e-04</td>\n",
       "      <td>1.615154e-04</td>\n",
       "      <td>0.253617</td>\n",
       "      <td>0.535517</td>\n",
       "      <td>0.574078</td>\n",
       "      <td>0.419068</td>\n",
       "      <td>0.540675</td>\n",
       "      <td>0.344139</td>\n",
       "      <td>0.620207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054843</td>\n",
       "      <td>0.254328</td>\n",
       "      <td>0.029776</td>\n",
       "      <td>0.023412</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.050626</td>\n",
       "      <td>0.333234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170958</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597571e-07</td>\n",
       "      <td>1.613001e-07</td>\n",
       "      <td>1.622171e-07</td>\n",
       "      <td>0.449158</td>\n",
       "      <td>0.426517</td>\n",
       "      <td>0.388795</td>\n",
       "      <td>0.316629</td>\n",
       "      <td>0.386062</td>\n",
       "      <td>0.277335</td>\n",
       "      <td>0.266238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   flatness    zerocr  meancent   stdcent   maxcent  pitchmean  pitchmax  \\\n",
       "0  0.115663  0.162883  0.240805  0.096425  0.182149   0.211254  0.439522   \n",
       "1  0.080613  0.127624  0.141372  0.075476  0.163086   0.397358  0.384960   \n",
       "2  0.070928  0.256826  0.189870  0.115045  0.241298   0.062928  0.252640   \n",
       "3  0.092065  0.411366  0.064047  0.045455  0.075815   0.087601  0.252379   \n",
       "4  0.054843  0.254328  0.029776  0.023412  0.036345   0.050626  0.333234   \n",
       "\n",
       "   pitchmin  pitchstd  pitch_tuning_offset  ...        mel126        mel127  \\\n",
       "0       0.0  0.372568             0.404040  ...  1.836009e-06  1.811076e-06   \n",
       "1       0.0  0.393772             0.191919  ...  4.120602e-07  4.103606e-07   \n",
       "2       0.0  0.161979             0.191919  ...  3.834468e-07  3.831249e-07   \n",
       "3       0.0  0.185685             0.808081  ...  1.635418e-04  1.622759e-04   \n",
       "4       0.0  0.170958             0.777778  ...  1.597571e-07  1.613001e-07   \n",
       "\n",
       "         mel128  contrast1  contrast2  contrast3  contrast4  contrast5  \\\n",
       "0  1.795984e-06   0.512331   0.301199   0.207383   0.211420   0.214275   \n",
       "1  4.093246e-07   0.460097   0.161483   0.198829   0.218364   0.296429   \n",
       "2  3.828833e-07   0.526381   0.382648   0.324490   0.421281   0.407452   \n",
       "3  1.615154e-04   0.253617   0.535517   0.574078   0.419068   0.540675   \n",
       "4  1.622171e-07   0.449158   0.426517   0.388795   0.316629   0.386062   \n",
       "\n",
       "   contrast6  contrast7  \n",
       "0   0.210560   0.539301  \n",
       "1   0.123045   0.626767  \n",
       "2   0.399111   0.420664  \n",
       "3   0.344139   0.620207  \n",
       "4   0.277335   0.266238  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled = min_max_scaler.fit_transform(train_raw)\n",
    "train_scaled = pd.DataFrame(scaled)\n",
    "train_scaled.columns = train_raw.columns\n",
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_scaled.values.astype(np.float32)\n",
    "target = audio_4emotions.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, stratify=target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2870"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 1063, 0: 749, 1: 363, 2: 695})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 174, 0: 187, 3: 266, 1: 91})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AudioDataset_train(Dataset):\n",
    "    \"\"\"\n",
    "    Diabetes Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.len = len(X_train)\n",
    "        self.x_data = torch.from_numpy(X_train)\n",
    "        self.y_data = torch.from_numpy(y_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "traindataset = AudioDataset_train()\n",
    "\n",
    "trainloader = DataLoader(dataset=traindataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AudioDataset_test(Dataset):\n",
    "    \"\"\"\n",
    "    Diabetes Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.len = len(X_test)\n",
    "        self.x_data = torch.from_numpy(X_test)\n",
    "        self.y_data = torch.from_numpy(y_test)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "testdataset = AudioDataset_test()\n",
    "\n",
    "testloader = DataLoader(dataset=testdataset,\n",
    "                          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 199]), torch.Size([128]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testiter = iter(testloader)\n",
    "features, labels = next(testiter)\n",
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(199, 300)\n",
    "#         self.l2 = nn.Linear(200, 100)\n",
    "#         self.l3 = nn.Linear(100, 50)\n",
    "#         self.l4 = nn.Linear(50, 4)\n",
    "        \n",
    "        self.l5 = nn.Linear(300, 4)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, x): # flattening (n, 1, 28, 28)--> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "#         x = F.relu(self.l2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = F.relu(self.l3(x))\n",
    "        x = self.dropout(x)\n",
    "        return F.softmax(self.l5(x))\n",
    "        \n",
    "        \n",
    "# intantiation\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu116\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
      "Collecting torch-scatter\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.0%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-sparse\n",
      "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.16%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/arpitsah/anaconda3/envs/domain_adaption/lib/python3.9/site-packages (from torch-sparse) (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /home/arpitsah/anaconda3/envs/domain_adaption/lib/python3.9/site-packages (from scipy->torch-sparse) (1.23.5)\n",
      "Installing collected packages: torch-scatter, torch-sparse\n",
      "Successfully installed torch-scatter-2.1.0+pt113cu116 torch-sparse-0.6.16+pt113cu116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network before turning off sparse layer 65454\n",
      "network after turning off sparse layer 65354\n"
     ]
    }
   ],
   "source": [
    "# With Affine Layer\n",
    "import torch.nn as nn\n",
    "from sparselinear import SparseLinear\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()#128*199\n",
    "        self.l1 = nn.Linear(199, 200)\n",
    "        self.l2 = nn.Linear(200, 100)\n",
    "        self.l3 = nn.Linear(100, 50)\n",
    "#         self.l4 = nn.Linear(50, 4)\n",
    "        self.sparse = SparseLinear(50, 50,sparsity =1- float(1/50))# replace with sparse \n",
    "        self.l5 = nn.Linear(50, 4) \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        \n",
    "    def forward(self, x): # flattening (n, 1, 28, 28)--> (n, 784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = self.sparse(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        return F.softmax(self.l5(x))\n",
    "        \n",
    "# instantiation\n",
    "\n",
    "net = Net()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)     \n",
    "\n",
    "print(\"network before turning off sparse layer\", count_parameters(net))\n",
    "\n",
    "for param in net.sparse.parameters():\n",
    "    param.requires_grad = False     \n",
    "\n",
    "\n",
    "print(\"network after turning off sparse layer\", count_parameters(net))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, labels):\n",
    "    cm = confusion_matrix(actual, predicted, labels)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, annot_kws={\"size\": 10}, fmt='.0f'); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anger = 0\n",
    "happiness = 0\n",
    "neutral = 0\n",
    "sadness = 0\n",
    "\n",
    "for _, target in trainloader:\n",
    "    labels = list(target.numpy())\n",
    "    anger += len([x for x in labels if x == 0])\n",
    "    happiness += len([x for x in labels if x == 1])\n",
    "    neutral += len([x for x in labels if x == 2])\n",
    "    sadness += len([x for x in labels if x == 3])\n",
    "    \n",
    "for _, target in testloader:\n",
    "    labels = list(target.numpy())\n",
    "    anger += len([x for x in labels if x == 0])\n",
    "    happiness += len([x for x in labels if x == 1])\n",
    "    neutral += len([x for x in labels if x == 2])\n",
    "    sadness += len([x for x in labels if x == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger 936 happiness 454 neutral 869 sadness 1329\n"
     ]
    }
   ],
   "source": [
    "print(\"anger {} happiness {} neutral {} sadness {}\".format(anger, happiness, neutral, sadness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0011, 0.0022, 0.0012, 0.0008], device='cuda:0')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = [1/anger, 1/happiness, 1/neutral, 1/sadness]\n",
    "class_weights = torch.FloatTensor(sample_weights).cuda()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_class = {0: 'anger', 1: 'happiness', 2: 'neutral', 3: 'sadness'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_labels = ['anger', 'happiness', 'neutral', 'sadness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network after turning off sparse layer 65354\n"
     ]
    }
   ],
   "source": [
    "# instantiation\n",
    "model = Net()\n",
    "print(\"network after turning off sparse layer\", count_parameters(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (l1): Linear(in_features=199, out_features=200, bias=True)\n",
       "  (l2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (l3): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (sparse): SparseLinear(in_features=50, out_features=50, bias=True, sparsity=0.98, connectivity=None, small_world=False)\n",
       "  (l5): Linear(in_features=50, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer and criterion\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.003)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "# exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(trainloader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        print(data.shape)\n",
    "        # zero the gradient, forward, backward and running pytorch rhythm\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        # get the label of prediction\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct_train += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\n'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader), loss.item()))\n",
    "    \n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    train_acc = 100. * correct_train / len(trainloader.dataset)\n",
    "    print('\\nTrain set: Average loss: {:.4f}\\n'.format(train_loss))\n",
    "    print('\\nTrain Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct_train, len(trainloader.dataset), 100. * correct_train / len(trainloader.dataset)))\n",
    "    \n",
    "    return train_loss, int(train_acc.numpy())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    correct = 0\n",
    "    history_test = []\n",
    "\n",
    "    pred_model = []\n",
    "    actual = []\n",
    "\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # output from model\n",
    "        output = model(data)\n",
    "\n",
    "        # sum total loss\n",
    "        test_loss += criterion(output, target).item()\n",
    "\n",
    "        # get the label of prediction\n",
    "        pred = torch.max(output.data, 1)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        pred_model.append(pred.cpu().numpy())\n",
    "        actual.append(target.data.cpu().numpy())\n",
    "\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    test_acc = 100. * correct / len(testloader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n",
    "\n",
    "\n",
    "    pred_with_label = [label_to_class[label] for label in list(np.concatenate(pred_model))]\n",
    "    actual_with_label = [label_to_class[label] for label in list(np.concatenate(actual))]\n",
    "\n",
    "    confusion_matrix(actual_with_label, pred_with_label, labels=final_labels)\n",
    "\n",
    "    print('\\n Classification Report \\n {} \\n'.format(classification_report(actual_with_label, pred_with_label)))\n",
    "\n",
    "    return test_loss, int(test_acc.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 199])\n",
      "Train Epoch: 1 [0/2870 (0%)]\tLoss: 1.390126\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 1 [1280/2870 (43%)]\tLoss: 1.385369\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 1 [2560/2870 (87%)]\tLoss: 1.357037\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0110\n",
      "\n",
      "\n",
      "Train Accuracy: 970/2870 (34%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 311/718 (43%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.39      0.95      0.55       187\n",
      "   happiness       0.00      0.00      0.00        91\n",
      "     neutral       0.51      0.77      0.62       174\n",
      "     sadness       0.00      0.00      0.00       266\n",
      "\n",
      "    accuracy                           0.43       718\n",
      "   macro avg       0.23      0.43      0.29       718\n",
      "weighted avg       0.23      0.43      0.29       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 2 [0/2870 (0%)]\tLoss: 1.317845\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 2 [1280/2870 (43%)]\tLoss: 1.355012\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 2 [2560/2870 (87%)]\tLoss: 1.320194\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0104\n",
      "\n",
      "\n",
      "Train Accuracy: 1215/2870 (42%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 339/718 (47%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.48      0.84      0.61       187\n",
      "   happiness       0.00      0.00      0.00        91\n",
      "     neutral       0.46      0.90      0.61       174\n",
      "     sadness       0.52      0.09      0.16       266\n",
      "\n",
      "    accuracy                           0.47       718\n",
      "   macro avg       0.36      0.46      0.34       718\n",
      "weighted avg       0.43      0.47      0.37       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 3 [0/2870 (0%)]\tLoss: 1.250838\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 3 [1280/2870 (43%)]\tLoss: 1.273451\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 3 [2560/2870 (87%)]\tLoss: 1.211381\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0101\n",
      "\n",
      "\n",
      "Train Accuracy: 1392/2870 (49%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 382/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.58      0.78      0.66       187\n",
      "   happiness       0.00      0.00      0.00        91\n",
      "     neutral       0.48      0.91      0.63       174\n",
      "     sadness       0.58      0.29      0.39       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.41      0.50      0.42       718\n",
      "weighted avg       0.48      0.53      0.47       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 4 [0/2870 (0%)]\tLoss: 1.238936\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 4 [1280/2870 (43%)]\tLoss: 1.264769\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 4 [2560/2870 (87%)]\tLoss: 1.223539\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0100\n",
      "\n",
      "\n",
      "Train Accuracy: 1370/2870 (48%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 407/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.77      0.69       187\n",
      "   happiness       0.15      0.05      0.08        91\n",
      "     neutral       0.55      0.80      0.65       174\n",
      "     sadness       0.59      0.44      0.51       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.48      0.52      0.48       718\n",
      "weighted avg       0.53      0.57      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 5 [0/2870 (0%)]\tLoss: 1.239054\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 5 [1280/2870 (43%)]\tLoss: 1.260744\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 5 [2560/2870 (87%)]\tLoss: 1.260311\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0099\n",
      "\n",
      "\n",
      "Train Accuracy: 1478/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 394/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.82      0.67       187\n",
      "   happiness       0.20      0.09      0.12        91\n",
      "     neutral       0.55      0.86      0.67       174\n",
      "     sadness       0.63      0.31      0.42       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.49      0.52      0.47       718\n",
      "weighted avg       0.54      0.55      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 6 [0/2870 (0%)]\tLoss: 1.245057\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 6 [1280/2870 (43%)]\tLoss: 1.168422\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 6 [2560/2870 (87%)]\tLoss: 1.241024\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0099\n",
      "\n",
      "\n",
      "Train Accuracy: 1455/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 397/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.83      0.67       187\n",
      "   happiness       0.20      0.08      0.11        91\n",
      "     neutral       0.58      0.74      0.65       174\n",
      "     sadness       0.58      0.39      0.47       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.48      0.51      0.48       718\n",
      "weighted avg       0.53      0.55      0.52       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 7 [0/2870 (0%)]\tLoss: 1.233495\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 7 [1280/2870 (43%)]\tLoss: 1.219675\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 7 [2560/2870 (87%)]\tLoss: 1.251669\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0098\n",
      "\n",
      "\n",
      "Train Accuracy: 1472/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 392/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.73      0.69       187\n",
      "   happiness       0.22      0.24      0.23        91\n",
      "     neutral       0.55      0.82      0.66       174\n",
      "     sadness       0.62      0.34      0.44       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.51      0.53      0.50       718\n",
      "weighted avg       0.56      0.55      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 8 [0/2870 (0%)]\tLoss: 1.205244\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 8 [1280/2870 (43%)]\tLoss: 1.234560\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 8 [2560/2870 (87%)]\tLoss: 1.245901\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1506/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 346/718 (48%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.55      0.86      0.67       187\n",
      "   happiness       0.19      0.25      0.22        91\n",
      "     neutral       0.59      0.63      0.61       174\n",
      "     sadness       0.42      0.20      0.27       266\n",
      "\n",
      "    accuracy                           0.48       718\n",
      "   macro avg       0.44      0.48      0.44       718\n",
      "weighted avg       0.47      0.48      0.45       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 9 [0/2870 (0%)]\tLoss: 1.223368\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 9 [1280/2870 (43%)]\tLoss: 1.197115\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 9 [2560/2870 (87%)]\tLoss: 1.195728\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1467/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 374/718 (52%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.60      0.81      0.69       187\n",
      "   happiness       0.18      0.20      0.19        91\n",
      "     neutral       0.56      0.77      0.65       174\n",
      "     sadness       0.56      0.26      0.36       266\n",
      "\n",
      "    accuracy                           0.52       718\n",
      "   macro avg       0.47      0.51      0.47       718\n",
      "weighted avg       0.52      0.52      0.49       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 10 [0/2870 (0%)]\tLoss: 1.247294\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 10 [1280/2870 (43%)]\tLoss: 1.154843\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 10 [2560/2870 (87%)]\tLoss: 1.251758\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0098\n",
      "\n",
      "\n",
      "Train Accuracy: 1477/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 331/718 (46%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.56      0.86      0.68       187\n",
      "   happiness       0.18      0.25      0.21        91\n",
      "     neutral       0.61      0.49      0.54       174\n",
      "     sadness       0.38      0.24      0.29       266\n",
      "\n",
      "    accuracy                           0.46       718\n",
      "   macro avg       0.43      0.46      0.43       718\n",
      "weighted avg       0.46      0.46      0.44       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 11 [0/2870 (0%)]\tLoss: 1.248854\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 11 [1280/2870 (43%)]\tLoss: 1.231817\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 11 [2560/2870 (87%)]\tLoss: 1.147696\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0098\n",
      "\n",
      "\n",
      "Train Accuracy: 1410/2870 (49%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 344/718 (48%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.51      0.87      0.65       187\n",
      "   happiness       0.18      0.18      0.18        91\n",
      "     neutral       0.60      0.62      0.61       174\n",
      "     sadness       0.44      0.21      0.29       266\n",
      "\n",
      "    accuracy                           0.48       718\n",
      "   macro avg       0.43      0.47      0.43       718\n",
      "weighted avg       0.46      0.48      0.44       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 12 [0/2870 (0%)]\tLoss: 1.262134\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 12 [1280/2870 (43%)]\tLoss: 1.162811\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 12 [2560/2870 (87%)]\tLoss: 1.203526\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0098\n",
      "\n",
      "\n",
      "Train Accuracy: 1454/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 391/718 (54%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.74      0.73       187\n",
      "   happiness       0.18      0.22      0.20        91\n",
      "     neutral       0.59      0.67      0.63       174\n",
      "     sadness       0.54      0.43      0.48       266\n",
      "\n",
      "    accuracy                           0.54       718\n",
      "   macro avg       0.51      0.52      0.51       718\n",
      "weighted avg       0.55      0.54      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 13 [0/2870 (0%)]\tLoss: 1.247788\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 13 [1280/2870 (43%)]\tLoss: 1.196489\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 13 [2560/2870 (87%)]\tLoss: 1.255128\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1507/2870 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 395/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.76      0.73       187\n",
      "   happiness       0.20      0.24      0.22        91\n",
      "     neutral       0.58      0.75      0.66       174\n",
      "     sadness       0.57      0.38      0.45       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.51      0.53      0.51       718\n",
      "weighted avg       0.56      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 14 [0/2870 (0%)]\tLoss: 1.248412\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 14 [1280/2870 (43%)]\tLoss: 1.261917\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 14 [2560/2870 (87%)]\tLoss: 1.184664\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1480/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 381/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.78      0.61      0.68       187\n",
      "   happiness       0.16      0.24      0.19        91\n",
      "     neutral       0.55      0.84      0.66       174\n",
      "     sadness       0.59      0.37      0.45       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.52      0.52      0.50       718\n",
      "weighted avg       0.58      0.53      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 15 [0/2870 (0%)]\tLoss: 1.147679\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 15 [1280/2870 (43%)]\tLoss: 1.207352\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 15 [2560/2870 (87%)]\tLoss: 1.229412\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1462/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 368/718 (51%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.74      0.73       187\n",
      "   happiness       0.19      0.33      0.24        91\n",
      "     neutral       0.53      0.86      0.66       174\n",
      "     sadness       0.57      0.19      0.28       266\n",
      "\n",
      "    accuracy                           0.51       718\n",
      "   macro avg       0.50      0.53      0.48       718\n",
      "weighted avg       0.55      0.51      0.48       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 16 [0/2870 (0%)]\tLoss: 1.193338\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 16 [1280/2870 (43%)]\tLoss: 1.204059\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 16 [2560/2870 (87%)]\tLoss: 1.175063\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0096\n",
      "\n",
      "\n",
      "Train Accuracy: 1481/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 395/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.81      0.61      0.70       187\n",
      "   happiness       0.15      0.16      0.16        91\n",
      "     neutral       0.53      0.86      0.66       174\n",
      "     sadness       0.59      0.44      0.50       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.52      0.52      0.50       718\n",
      "weighted avg       0.58      0.55      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 17 [0/2870 (0%)]\tLoss: 1.171644\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 17 [1280/2870 (43%)]\tLoss: 1.187549\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 17 [2560/2870 (87%)]\tLoss: 1.202495\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0098\n",
      "\n",
      "\n",
      "Train Accuracy: 1415/2870 (49%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 378/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.60      0.84      0.70       187\n",
      "   happiness       0.23      0.29      0.25        91\n",
      "     neutral       0.59      0.73      0.65       174\n",
      "     sadness       0.54      0.25      0.34       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.49      0.53      0.49       718\n",
      "weighted avg       0.53      0.53      0.50       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 18 [0/2870 (0%)]\tLoss: 1.268531\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 18 [1280/2870 (43%)]\tLoss: 1.210475\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 18 [2560/2870 (87%)]\tLoss: 1.117326\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0097\n",
      "\n",
      "\n",
      "Train Accuracy: 1498/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 369/718 (51%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.80      0.74       187\n",
      "   happiness       0.24      0.44      0.31        91\n",
      "     neutral       0.59      0.64      0.62       174\n",
      "     sadness       0.48      0.25      0.33       266\n",
      "\n",
      "    accuracy                           0.51       718\n",
      "   macro avg       0.50      0.53      0.50       718\n",
      "weighted avg       0.53      0.51      0.50       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 19 [0/2870 (0%)]\tLoss: 1.257665\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 19 [1280/2870 (43%)]\tLoss: 1.170323\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 19 [2560/2870 (87%)]\tLoss: 1.120741\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1481/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 382/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.82      0.74       187\n",
      "   happiness       0.24      0.41      0.30        91\n",
      "     neutral       0.60      0.71      0.65       174\n",
      "     sadness       0.52      0.26      0.34       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.51      0.55      0.51       718\n",
      "weighted avg       0.55      0.53      0.52       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 20 [0/2870 (0%)]\tLoss: 1.183307\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 20 [1280/2870 (43%)]\tLoss: 1.190530\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 20 [2560/2870 (87%)]\tLoss: 1.169225\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1508/2870 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 380/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.76      0.74       187\n",
      "   happiness       0.22      0.40      0.28        91\n",
      "     neutral       0.59      0.74      0.66       174\n",
      "     sadness       0.53      0.27      0.36       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.52      0.54      0.51       718\n",
      "weighted avg       0.55      0.53      0.52       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 21 [0/2870 (0%)]\tLoss: 1.202848\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 21 [1280/2870 (43%)]\tLoss: 1.162367\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 21 [2560/2870 (87%)]\tLoss: 1.167011\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1476/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 394/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.79      0.75       187\n",
      "   happiness       0.23      0.35      0.28        91\n",
      "     neutral       0.58      0.78      0.66       174\n",
      "     sadness       0.57      0.30      0.39       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.52      0.55      0.52       718\n",
      "weighted avg       0.57      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 22 [0/2870 (0%)]\tLoss: 1.189113\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 22 [1280/2870 (43%)]\tLoss: 1.180199\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 22 [2560/2870 (87%)]\tLoss: 1.248894\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1521/2870 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 404/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.77      0.74       187\n",
      "   happiness       0.23      0.27      0.25        91\n",
      "     neutral       0.58      0.76      0.66       174\n",
      "     sadness       0.57      0.38      0.46       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.52      0.55      0.53       718\n",
      "weighted avg       0.57      0.56      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 23 [0/2870 (0%)]\tLoss: 1.169002\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 23 [1280/2870 (43%)]\tLoss: 1.188215\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 23 [2560/2870 (87%)]\tLoss: 1.250221\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1568/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 365/718 (51%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.83      0.72       187\n",
      "   happiness       0.24      0.44      0.31        91\n",
      "     neutral       0.61      0.66      0.63       174\n",
      "     sadness       0.46      0.21      0.29       266\n",
      "\n",
      "    accuracy                           0.51       718\n",
      "   macro avg       0.49      0.53      0.49       718\n",
      "weighted avg       0.51      0.51      0.49       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 24 [0/2870 (0%)]\tLoss: 1.193623\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 24 [1280/2870 (43%)]\tLoss: 1.203435\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 24 [2560/2870 (87%)]\tLoss: 1.185000\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0096\n",
      "\n",
      "\n",
      "Train Accuracy: 1453/2870 (51%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 384/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.51      0.65       187\n",
      "   happiness       0.18      0.32      0.23        91\n",
      "     neutral       0.55      0.84      0.67       174\n",
      "     sadness       0.60      0.42      0.50       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.56      0.52      0.51       718\n",
      "weighted avg       0.61      0.53      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 25 [0/2870 (0%)]\tLoss: 1.232173\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 25 [1280/2870 (43%)]\tLoss: 1.194391\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 25 [2560/2870 (87%)]\tLoss: 1.237047\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1563/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 381/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.82      0.73       187\n",
      "   happiness       0.27      0.45      0.34        91\n",
      "     neutral       0.60      0.71      0.65       174\n",
      "     sadness       0.50      0.24      0.32       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.51      0.55      0.51       718\n",
      "weighted avg       0.54      0.53      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 26 [0/2870 (0%)]\tLoss: 1.192594\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 26 [1280/2870 (43%)]\tLoss: 1.219207\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 26 [2560/2870 (87%)]\tLoss: 1.134803\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1526/2870 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 400/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.76      0.73      0.75       187\n",
      "   happiness       0.22      0.29      0.25        91\n",
      "     neutral       0.55      0.86      0.67       174\n",
      "     sadness       0.60      0.33      0.43       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.55      0.52       718\n",
      "weighted avg       0.58      0.56      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 27 [0/2870 (0%)]\tLoss: 1.163966\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 27 [1280/2870 (43%)]\tLoss: 1.212446\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 27 [2560/2870 (87%)]\tLoss: 1.151044\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1553/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 375/718 (52%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.83      0.73       187\n",
      "   happiness       0.26      0.45      0.33        91\n",
      "     neutral       0.60      0.71      0.65       174\n",
      "     sadness       0.48      0.21      0.29       266\n",
      "\n",
      "    accuracy                           0.52       718\n",
      "   macro avg       0.50      0.55      0.50       718\n",
      "weighted avg       0.53      0.52      0.50       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 28 [0/2870 (0%)]\tLoss: 1.146211\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 28 [1280/2870 (43%)]\tLoss: 1.105492\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 28 [2560/2870 (87%)]\tLoss: 1.170849\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1558/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 412/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.82      0.75       187\n",
      "   happiness       0.28      0.27      0.28        91\n",
      "     neutral       0.54      0.86      0.66       174\n",
      "     sadness       0.64      0.32      0.42       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.54      0.57      0.53       718\n",
      "weighted avg       0.58      0.57      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 29 [0/2870 (0%)]\tLoss: 1.197409\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 29 [1280/2870 (43%)]\tLoss: 1.166239\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 29 [2560/2870 (87%)]\tLoss: 1.240400\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1546/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 395/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.83      0.74       187\n",
      "   happiness       0.27      0.41      0.32        91\n",
      "     neutral       0.60      0.76      0.67       174\n",
      "     sadness       0.56      0.26      0.35       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.52      0.57      0.52       718\n",
      "weighted avg       0.56      0.55      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 30 [0/2870 (0%)]\tLoss: 1.154265\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 30 [1280/2870 (43%)]\tLoss: 1.147010\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 30 [2560/2870 (87%)]\tLoss: 1.179461\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1509/2870 (53%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 384/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.87      0.58      0.70       187\n",
      "   happiness       0.21      0.48      0.30        91\n",
      "     neutral       0.60      0.79      0.68       174\n",
      "     sadness       0.59      0.35      0.44       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.57      0.55      0.53       718\n",
      "weighted avg       0.62      0.53      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 31 [0/2870 (0%)]\tLoss: 1.239820\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 31 [1280/2870 (43%)]\tLoss: 1.158486\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 31 [2560/2870 (87%)]\tLoss: 1.101692\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1594/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 404/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.60      0.86      0.71       187\n",
      "   happiness       0.33      0.33      0.33        91\n",
      "     neutral       0.61      0.78      0.68       174\n",
      "     sadness       0.57      0.29      0.39       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.56      0.53       718\n",
      "weighted avg       0.56      0.56      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 32 [0/2870 (0%)]\tLoss: 1.229607\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 32 [1280/2870 (43%)]\tLoss: 1.167494\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 32 [2560/2870 (87%)]\tLoss: 1.139601\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1554/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 409/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.77      0.72      0.75       187\n",
      "   happiness       0.28      0.42      0.33        91\n",
      "     neutral       0.53      0.86      0.66       174\n",
      "     sadness       0.68      0.32      0.44       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.57      0.58      0.54       718\n",
      "weighted avg       0.62      0.57      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 33 [0/2870 (0%)]\tLoss: 1.206033\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 33 [1280/2870 (43%)]\tLoss: 1.250208\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 33 [2560/2870 (87%)]\tLoss: 1.137542\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1482/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 378/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.84      0.72       187\n",
      "   happiness       0.27      0.44      0.33        91\n",
      "     neutral       0.63      0.64      0.64       174\n",
      "     sadness       0.48      0.26      0.33       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.50      0.55      0.51       718\n",
      "weighted avg       0.53      0.53      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 34 [0/2870 (0%)]\tLoss: 1.193722\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 34 [1280/2870 (43%)]\tLoss: 1.225685\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 34 [2560/2870 (87%)]\tLoss: 1.146232\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1600/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 392/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.78      0.74      0.76       187\n",
      "   happiness       0.24      0.44      0.31        91\n",
      "     neutral       0.57      0.79      0.67       174\n",
      "     sadness       0.58      0.29      0.38       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.54      0.56      0.53       718\n",
      "weighted avg       0.58      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 35 [0/2870 (0%)]\tLoss: 1.096654\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 35 [1280/2870 (43%)]\tLoss: 1.167482\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 35 [2560/2870 (87%)]\tLoss: 1.071262\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1634/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 416/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.84      0.75       187\n",
      "   happiness       0.34      0.36      0.35        91\n",
      "     neutral       0.57      0.82      0.67       174\n",
      "     sadness       0.61      0.32      0.42       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.55      0.58      0.55       718\n",
      "weighted avg       0.58      0.58      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 36 [0/2870 (0%)]\tLoss: 1.188337\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 36 [1280/2870 (43%)]\tLoss: 1.177991\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 36 [2560/2870 (87%)]\tLoss: 1.170285\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1606/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 394/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.80      0.70      0.75       187\n",
      "   happiness       0.24      0.46      0.32        91\n",
      "     neutral       0.58      0.81      0.67       174\n",
      "     sadness       0.59      0.30      0.40       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.55      0.57      0.53       718\n",
      "weighted avg       0.60      0.55      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 37 [0/2870 (0%)]\tLoss: 1.144427\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 37 [1280/2870 (43%)]\tLoss: 1.178000\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 37 [2560/2870 (87%)]\tLoss: 1.179812\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1503/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 393/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.74      0.78      0.76       187\n",
      "   happiness       0.25      0.47      0.33        91\n",
      "     neutral       0.60      0.76      0.68       174\n",
      "     sadness       0.55      0.27      0.36       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.54      0.57      0.53       718\n",
      "weighted avg       0.58      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 38 [0/2870 (0%)]\tLoss: 1.136094\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 38 [1280/2870 (43%)]\tLoss: 1.124487\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 38 [2560/2870 (87%)]\tLoss: 1.154103\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1618/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 430/718 (60%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.81      0.76       187\n",
      "   happiness       0.31      0.32      0.31        91\n",
      "     neutral       0.60      0.79      0.68       174\n",
      "     sadness       0.61      0.42      0.50       266\n",
      "\n",
      "    accuracy                           0.60       718\n",
      "   macro avg       0.56      0.58      0.56       718\n",
      "weighted avg       0.60      0.60      0.59       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 39 [0/2870 (0%)]\tLoss: 1.201106\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 39 [1280/2870 (43%)]\tLoss: 1.143844\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 39 [2560/2870 (87%)]\tLoss: 1.260742\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1585/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 419/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.79      0.76       187\n",
      "   happiness       0.31      0.38      0.34        91\n",
      "     neutral       0.56      0.83      0.67       174\n",
      "     sadness       0.64      0.35      0.45       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.59      0.55       718\n",
      "weighted avg       0.60      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 40 [0/2870 (0%)]\tLoss: 1.218654\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 40 [1280/2870 (43%)]\tLoss: 1.183062\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 40 [2560/2870 (87%)]\tLoss: 1.189169\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1644/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 389/718 (54%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.61      0.84      0.71       187\n",
      "   happiness       0.32      0.44      0.37        91\n",
      "     neutral       0.64      0.67      0.65       174\n",
      "     sadness       0.50      0.28      0.36       266\n",
      "\n",
      "    accuracy                           0.54       718\n",
      "   macro avg       0.52      0.56      0.52       718\n",
      "weighted avg       0.54      0.54      0.52       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 41 [0/2870 (0%)]\tLoss: 1.167876\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 41 [1280/2870 (43%)]\tLoss: 1.135625\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 41 [2560/2870 (87%)]\tLoss: 1.128454\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1619/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 417/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.79      0.73      0.76       187\n",
      "   happiness       0.30      0.35      0.32        91\n",
      "     neutral       0.52      0.89      0.65       174\n",
      "     sadness       0.68      0.36      0.47       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.57      0.58      0.55       718\n",
      "weighted avg       0.62      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 42 [0/2870 (0%)]\tLoss: 1.167132\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 42 [1280/2870 (43%)]\tLoss: 1.174298\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 42 [2560/2870 (87%)]\tLoss: 1.118274\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1616/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 396/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.82      0.75       187\n",
      "   happiness       0.28      0.46      0.35        91\n",
      "     neutral       0.60      0.77      0.67       174\n",
      "     sadness       0.54      0.25      0.34       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.53      0.58      0.53       718\n",
      "weighted avg       0.56      0.55      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 43 [0/2870 (0%)]\tLoss: 1.174007\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 43 [1280/2870 (43%)]\tLoss: 1.198514\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 43 [2560/2870 (87%)]\tLoss: 1.187117\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1547/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 392/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.89      0.55      0.68       187\n",
      "   happiness       0.23      0.42      0.30        91\n",
      "     neutral       0.53      0.88      0.66       174\n",
      "     sadness       0.66      0.37      0.47       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.58      0.55      0.53       718\n",
      "weighted avg       0.63      0.55      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 44 [0/2870 (0%)]\tLoss: 1.155366\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 44 [1280/2870 (43%)]\tLoss: 1.177286\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 44 [2560/2870 (87%)]\tLoss: 1.125300\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1567/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 405/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.82      0.74       187\n",
      "   happiness       0.29      0.38      0.33        91\n",
      "     neutral       0.61      0.75      0.67       174\n",
      "     sadness       0.55      0.32      0.40       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.57      0.54       718\n",
      "weighted avg       0.56      0.56      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 45 [0/2870 (0%)]\tLoss: 1.098662\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 45 [1280/2870 (43%)]\tLoss: 1.179348\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 45 [2560/2870 (87%)]\tLoss: 1.157089\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1653/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 418/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.84      0.72       187\n",
      "   happiness       0.34      0.33      0.34        91\n",
      "     neutral       0.62      0.76      0.68       174\n",
      "     sadness       0.58      0.37      0.45       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.54      0.58      0.55       718\n",
      "weighted avg       0.57      0.58      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 46 [0/2870 (0%)]\tLoss: 1.149212\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 46 [1280/2870 (43%)]\tLoss: 1.156092\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 46 [2560/2870 (87%)]\tLoss: 1.099425\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1637/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 414/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.82      0.75       187\n",
      "   happiness       0.39      0.34      0.36        91\n",
      "     neutral       0.50      0.91      0.65       174\n",
      "     sadness       0.71      0.26      0.38       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.57      0.59      0.54       718\n",
      "weighted avg       0.61      0.58      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 47 [0/2870 (0%)]\tLoss: 1.193976\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 47 [1280/2870 (43%)]\tLoss: 1.179885\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 47 [2560/2870 (87%)]\tLoss: 1.105299\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1577/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 418/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.82      0.67      0.74       187\n",
      "   happiness       0.25      0.29      0.26        91\n",
      "     neutral       0.55      0.88      0.68       174\n",
      "     sadness       0.63      0.42      0.51       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.57      0.55       718\n",
      "weighted avg       0.61      0.58      0.58       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 48 [0/2870 (0%)]\tLoss: 1.113824\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 48 [1280/2870 (43%)]\tLoss: 1.158618\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 48 [2560/2870 (87%)]\tLoss: 1.261399\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1585/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 377/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.80      0.72       187\n",
      "   happiness       0.28      0.52      0.36        91\n",
      "     neutral       0.62      0.69      0.65       174\n",
      "     sadness       0.48      0.23      0.31       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.51      0.56      0.51       718\n",
      "weighted avg       0.53      0.53      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 49 [0/2870 (0%)]\tLoss: 1.175196\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 49 [1280/2870 (43%)]\tLoss: 1.127399\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 49 [2560/2870 (87%)]\tLoss: 1.104501\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1610/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 391/718 (54%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.75      0.73       187\n",
      "   happiness       0.25      0.45      0.32        91\n",
      "     neutral       0.62      0.72      0.67       174\n",
      "     sadness       0.53      0.32      0.40       266\n",
      "\n",
      "    accuracy                           0.54       718\n",
      "   macro avg       0.53      0.56      0.53       718\n",
      "weighted avg       0.57      0.54      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 50 [0/2870 (0%)]\tLoss: 1.134905\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 50 [1280/2870 (43%)]\tLoss: 1.200282\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 50 [2560/2870 (87%)]\tLoss: 1.116576\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1601/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 419/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.75      0.74       187\n",
      "   happiness       0.32      0.38      0.35        91\n",
      "     neutral       0.55      0.87      0.67       174\n",
      "     sadness       0.66      0.35      0.46       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.59      0.55       718\n",
      "weighted avg       0.61      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 51 [0/2870 (0%)]\tLoss: 1.155632\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 51 [1280/2870 (43%)]\tLoss: 1.191230\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 51 [2560/2870 (87%)]\tLoss: 1.194205\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1636/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 397/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.80      0.74       187\n",
      "   happiness       0.28      0.41      0.33        91\n",
      "     neutral       0.56      0.83      0.67       174\n",
      "     sadness       0.59      0.25      0.35       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.53      0.57      0.52       718\n",
      "weighted avg       0.57      0.55      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 52 [0/2870 (0%)]\tLoss: 1.065104\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 52 [1280/2870 (43%)]\tLoss: 1.201701\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 52 [2560/2870 (87%)]\tLoss: 1.167133\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1588/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 437/718 (61%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.80      0.75       187\n",
      "   happiness       0.39      0.33      0.36        91\n",
      "     neutral       0.58      0.80      0.67       174\n",
      "     sadness       0.64      0.44      0.52       266\n",
      "\n",
      "    accuracy                           0.61       718\n",
      "   macro avg       0.58      0.59      0.57       718\n",
      "weighted avg       0.61      0.61      0.60       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 53 [0/2870 (0%)]\tLoss: 1.103850\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 53 [1280/2870 (43%)]\tLoss: 1.151625\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 53 [2560/2870 (87%)]\tLoss: 1.147058\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1646/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 391/718 (54%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.59      0.84      0.70       187\n",
      "   happiness       0.36      0.42      0.39        91\n",
      "     neutral       0.57      0.79      0.67       174\n",
      "     sadness       0.54      0.21      0.31       266\n",
      "\n",
      "    accuracy                           0.54       718\n",
      "   macro avg       0.52      0.57      0.51       718\n",
      "weighted avg       0.54      0.54      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 54 [0/2870 (0%)]\tLoss: 1.110274\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 54 [1280/2870 (43%)]\tLoss: 1.160345\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 54 [2560/2870 (87%)]\tLoss: 1.170384\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0095\n",
      "\n",
      "\n",
      "Train Accuracy: 1493/2870 (52%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 422/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.83      0.73       187\n",
      "   happiness       0.41      0.32      0.36        91\n",
      "     neutral       0.55      0.86      0.67       174\n",
      "     sadness       0.65      0.33      0.44       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.57      0.59      0.55       718\n",
      "weighted avg       0.60      0.59      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 55 [0/2870 (0%)]\tLoss: 1.128255\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 55 [1280/2870 (43%)]\tLoss: 1.152375\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 55 [2560/2870 (87%)]\tLoss: 1.177882\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1560/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 398/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.82      0.74       187\n",
      "   happiness       0.29      0.40      0.33        91\n",
      "     neutral       0.61      0.72      0.66       174\n",
      "     sadness       0.53      0.31      0.39       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.52      0.56      0.53       718\n",
      "weighted avg       0.55      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 56 [0/2870 (0%)]\tLoss: 1.132656\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 56 [1280/2870 (43%)]\tLoss: 1.070273\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 56 [2560/2870 (87%)]\tLoss: 1.186177\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1632/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 412/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.84      0.73       187\n",
      "   happiness       0.36      0.34      0.35        91\n",
      "     neutral       0.56      0.82      0.67       174\n",
      "     sadness       0.60      0.31      0.41       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.54      0.58      0.54       718\n",
      "weighted avg       0.57      0.57      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 57 [0/2870 (0%)]\tLoss: 1.120878\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 57 [1280/2870 (43%)]\tLoss: 1.161475\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 57 [2560/2870 (87%)]\tLoss: 1.172982\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1610/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 420/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.79      0.74       187\n",
      "   happiness       0.34      0.38      0.36        91\n",
      "     neutral       0.57      0.80      0.67       174\n",
      "     sadness       0.62      0.36      0.46       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.59      0.56       718\n",
      "weighted avg       0.59      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 58 [0/2870 (0%)]\tLoss: 1.179365\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 58 [1280/2870 (43%)]\tLoss: 1.175590\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 58 [2560/2870 (87%)]\tLoss: 1.158095\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1636/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 417/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.76      0.78      0.77       187\n",
      "   happiness       0.29      0.41      0.34        91\n",
      "     neutral       0.56      0.86      0.68       174\n",
      "     sadness       0.65      0.32      0.43       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.59      0.55       718\n",
      "weighted avg       0.61      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 59 [0/2870 (0%)]\tLoss: 1.114305\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 59 [1280/2870 (43%)]\tLoss: 1.210654\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 59 [2560/2870 (87%)]\tLoss: 1.185631\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1546/2870 (54%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 404/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.83      0.73       187\n",
      "   happiness       0.32      0.36      0.34        91\n",
      "     neutral       0.59      0.79      0.67       174\n",
      "     sadness       0.55      0.29      0.38       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.57      0.53       718\n",
      "weighted avg       0.56      0.56      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 60 [0/2870 (0%)]\tLoss: 1.160019\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 60 [1280/2870 (43%)]\tLoss: 1.190913\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 60 [2560/2870 (87%)]\tLoss: 1.151706\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1637/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 406/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.73      0.72       187\n",
      "   happiness       0.27      0.43      0.33        91\n",
      "     neutral       0.62      0.77      0.69       174\n",
      "     sadness       0.57      0.36      0.44       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.55      0.57      0.55       718\n",
      "weighted avg       0.58      0.57      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 61 [0/2870 (0%)]\tLoss: 1.182901\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 61 [1280/2870 (43%)]\tLoss: 1.169295\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 61 [2560/2870 (87%)]\tLoss: 1.154406\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1655/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 404/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.81      0.74       187\n",
      "   happiness       0.30      0.41      0.34        91\n",
      "     neutral       0.60      0.79      0.68       174\n",
      "     sadness       0.57      0.29      0.39       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.58      0.54       718\n",
      "weighted avg       0.57      0.56      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 62 [0/2870 (0%)]\tLoss: 1.105928\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 62 [1280/2870 (43%)]\tLoss: 1.130908\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 62 [2560/2870 (87%)]\tLoss: 1.126640\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1661/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 412/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.75      0.77      0.76       187\n",
      "   happiness       0.30      0.40      0.34        91\n",
      "     neutral       0.54      0.88      0.67       174\n",
      "     sadness       0.65      0.30      0.41       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.56      0.59      0.54       718\n",
      "weighted avg       0.61      0.57      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 63 [0/2870 (0%)]\tLoss: 1.144741\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 63 [1280/2870 (43%)]\tLoss: 1.176303\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 63 [2560/2870 (87%)]\tLoss: 1.110985\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1613/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 430/718 (60%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.74      0.77      0.76       187\n",
      "   happiness       0.34      0.41      0.37        91\n",
      "     neutral       0.59      0.80      0.68       174\n",
      "     sadness       0.62      0.41      0.49       266\n",
      "\n",
      "    accuracy                           0.60       718\n",
      "   macro avg       0.57      0.60      0.57       718\n",
      "weighted avg       0.61      0.60      0.59       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 64 [0/2870 (0%)]\tLoss: 1.173321\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 64 [1280/2870 (43%)]\tLoss: 1.095056\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 64 [2560/2870 (87%)]\tLoss: 1.145462\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1668/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 413/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.74      0.78      0.76       187\n",
      "   happiness       0.29      0.45      0.35        91\n",
      "     neutral       0.62      0.75      0.68       174\n",
      "     sadness       0.56      0.36      0.44       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.55      0.58      0.56       718\n",
      "weighted avg       0.59      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 65 [0/2870 (0%)]\tLoss: 1.119643\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 65 [1280/2870 (43%)]\tLoss: 1.138209\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 65 [2560/2870 (87%)]\tLoss: 1.085782\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1671/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 423/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.82      0.74       187\n",
      "   happiness       0.40      0.36      0.38        91\n",
      "     neutral       0.57      0.82      0.67       174\n",
      "     sadness       0.60      0.35      0.44       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.56      0.59      0.56       718\n",
      "weighted avg       0.59      0.59      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 66 [0/2870 (0%)]\tLoss: 1.101525\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 66 [1280/2870 (43%)]\tLoss: 1.173824\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 66 [2560/2870 (87%)]\tLoss: 1.200487\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1701/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 410/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.77      0.70      0.73       187\n",
      "   happiness       0.27      0.44      0.34        91\n",
      "     neutral       0.60      0.77      0.67       174\n",
      "     sadness       0.59      0.40      0.48       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.56      0.58      0.55       718\n",
      "weighted avg       0.60      0.57      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 67 [0/2870 (0%)]\tLoss: 1.144484\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 67 [1280/2870 (43%)]\tLoss: 1.108646\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 67 [2560/2870 (87%)]\tLoss: 1.131832\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1678/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 400/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.82      0.73       187\n",
      "   happiness       0.32      0.46      0.38        91\n",
      "     neutral       0.61      0.74      0.67       174\n",
      "     sadness       0.53      0.29      0.37       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.58      0.54       718\n",
      "weighted avg       0.56      0.56      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 68 [0/2870 (0%)]\tLoss: 1.198034\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 68 [1280/2870 (43%)]\tLoss: 1.161842\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 68 [2560/2870 (87%)]\tLoss: 1.090146\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1670/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 419/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.79      0.72      0.76       187\n",
      "   happiness       0.29      0.44      0.35        91\n",
      "     neutral       0.59      0.80      0.68       174\n",
      "     sadness       0.60      0.39      0.48       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.57      0.59      0.57       718\n",
      "weighted avg       0.61      0.58      0.58       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 69 [0/2870 (0%)]\tLoss: 1.188603\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 69 [1280/2870 (43%)]\tLoss: 1.086166\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 69 [2560/2870 (87%)]\tLoss: 1.139735\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1658/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 396/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.65      0.84      0.73       187\n",
      "   happiness       0.33      0.45      0.38        91\n",
      "     neutral       0.64      0.66      0.65       174\n",
      "     sadness       0.49      0.31      0.38       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.53      0.57      0.54       718\n",
      "weighted avg       0.55      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 70 [0/2870 (0%)]\tLoss: 1.198362\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 70 [1280/2870 (43%)]\tLoss: 1.121269\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 70 [2560/2870 (87%)]\tLoss: 1.130778\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1659/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 439/718 (61%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.79      0.76       187\n",
      "   happiness       0.39      0.36      0.38        91\n",
      "     neutral       0.56      0.86      0.68       174\n",
      "     sadness       0.66      0.41      0.51       266\n",
      "\n",
      "    accuracy                           0.61       718\n",
      "   macro avg       0.59      0.61      0.58       718\n",
      "weighted avg       0.62      0.61      0.60       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 71 [0/2870 (0%)]\tLoss: 1.160751\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 71 [1280/2870 (43%)]\tLoss: 1.123040\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 71 [2560/2870 (87%)]\tLoss: 1.125713\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1666/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 414/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.84      0.73       187\n",
      "   happiness       0.38      0.35      0.37        91\n",
      "     neutral       0.57      0.82      0.67       174\n",
      "     sadness       0.58      0.31      0.40       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.54      0.58      0.54       718\n",
      "weighted avg       0.57      0.58      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 72 [0/2870 (0%)]\tLoss: 1.167148\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 72 [1280/2870 (43%)]\tLoss: 1.165833\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 72 [2560/2870 (87%)]\tLoss: 1.138265\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1632/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 413/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.72      0.78      0.75       187\n",
      "   happiness       0.30      0.44      0.36        91\n",
      "     neutral       0.59      0.82      0.69       174\n",
      "     sadness       0.60      0.32      0.42       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.55      0.59      0.55       718\n",
      "weighted avg       0.59      0.58      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 73 [0/2870 (0%)]\tLoss: 1.055583\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 73 [1280/2870 (43%)]\tLoss: 1.125184\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 73 [2560/2870 (87%)]\tLoss: 1.164911\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1713/2870 (60%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 397/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.62      0.86      0.72       187\n",
      "   happiness       0.37      0.43      0.40        91\n",
      "     neutral       0.65      0.63      0.64       174\n",
      "     sadness       0.48      0.33      0.39       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.53      0.56      0.54       718\n",
      "weighted avg       0.54      0.55      0.54       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 74 [0/2870 (0%)]\tLoss: 1.172444\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 74 [1280/2870 (43%)]\tLoss: 1.138736\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 74 [2560/2870 (87%)]\tLoss: 1.164822\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1686/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 410/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.76      0.75      0.76       187\n",
      "   happiness       0.29      0.45      0.35        91\n",
      "     neutral       0.57      0.84      0.68       174\n",
      "     sadness       0.61      0.31      0.41       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.56      0.59      0.55       718\n",
      "weighted avg       0.60      0.57      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 75 [0/2870 (0%)]\tLoss: 1.160469\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 75 [1280/2870 (43%)]\tLoss: 1.195786\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 75 [2560/2870 (87%)]\tLoss: 1.076623\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1682/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 403/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.57      0.86      0.69       187\n",
      "   happiness       0.40      0.40      0.40        91\n",
      "     neutral       0.61      0.78      0.68       174\n",
      "     sadness       0.57      0.27      0.36       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.54      0.57      0.53       718\n",
      "weighted avg       0.56      0.56      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 76 [0/2870 (0%)]\tLoss: 1.136649\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 76 [1280/2870 (43%)]\tLoss: 1.056860\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 76 [2560/2870 (87%)]\tLoss: 1.141783\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1644/2870 (57%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 436/718 (61%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.84      0.68      0.75       187\n",
      "   happiness       0.36      0.32      0.34        91\n",
      "     neutral       0.53      0.89      0.66       174\n",
      "     sadness       0.64      0.47      0.54       266\n",
      "\n",
      "    accuracy                           0.61       718\n",
      "   macro avg       0.59      0.59      0.57       718\n",
      "weighted avg       0.63      0.61      0.60       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 77 [0/2870 (0%)]\tLoss: 1.115386\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 77 [1280/2870 (43%)]\tLoss: 1.094166\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 77 [2560/2870 (87%)]\tLoss: 1.120836\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1673/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 367/718 (51%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.83      0.75       187\n",
      "   happiness       0.24      0.48      0.32        91\n",
      "     neutral       0.61      0.66      0.63       174\n",
      "     sadness       0.44      0.20      0.28       266\n",
      "\n",
      "    accuracy                           0.51       718\n",
      "   macro avg       0.49      0.54      0.50       718\n",
      "weighted avg       0.52      0.51      0.49       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 78 [0/2870 (0%)]\tLoss: 1.164401\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 78 [1280/2870 (43%)]\tLoss: 1.122294\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 78 [2560/2870 (87%)]\tLoss: 1.082980\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1655/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 426/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.82      0.75       187\n",
      "   happiness       0.36      0.37      0.37        91\n",
      "     neutral       0.60      0.75      0.67       174\n",
      "     sadness       0.58      0.41      0.48       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.56      0.59      0.57       718\n",
      "weighted avg       0.59      0.59      0.58       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 79 [0/2870 (0%)]\tLoss: 1.121297\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 79 [1280/2870 (43%)]\tLoss: 1.148093\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 79 [2560/2870 (87%)]\tLoss: 1.034997\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1608/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 425/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.60      0.86      0.71       187\n",
      "   happiness       0.59      0.25      0.35        91\n",
      "     neutral       0.56      0.87      0.68       174\n",
      "     sadness       0.65      0.34      0.44       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.60      0.58      0.55       718\n",
      "weighted avg       0.61      0.59      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 80 [0/2870 (0%)]\tLoss: 1.195732\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 80 [1280/2870 (43%)]\tLoss: 1.132626\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 80 [2560/2870 (87%)]\tLoss: 1.164589\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1687/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 379/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.78      0.72      0.75       187\n",
      "   happiness       0.25      0.54      0.34        91\n",
      "     neutral       0.56      0.80      0.66       174\n",
      "     sadness       0.54      0.21      0.30       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.53      0.57      0.51       718\n",
      "weighted avg       0.57      0.53      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 81 [0/2870 (0%)]\tLoss: 1.194832\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 81 [1280/2870 (43%)]\tLoss: 1.100461\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 81 [2560/2870 (87%)]\tLoss: 1.163349\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1582/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 413/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.83      0.64      0.72       187\n",
      "   happiness       0.29      0.46      0.36        91\n",
      "     neutral       0.59      0.80      0.68       174\n",
      "     sadness       0.57      0.42      0.49       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.57      0.58      0.56       718\n",
      "weighted avg       0.61      0.58      0.58       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 82 [0/2870 (0%)]\tLoss: 1.186211\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 82 [1280/2870 (43%)]\tLoss: 1.170149\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 82 [2560/2870 (87%)]\tLoss: 1.114753\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1656/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 379/718 (53%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.79      0.75       187\n",
      "   happiness       0.26      0.51      0.34        91\n",
      "     neutral       0.61      0.71      0.65       174\n",
      "     sadness       0.49      0.23      0.32       266\n",
      "\n",
      "    accuracy                           0.53       718\n",
      "   macro avg       0.52      0.56      0.51       718\n",
      "weighted avg       0.55      0.53      0.51       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 83 [0/2870 (0%)]\tLoss: 1.210056\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 83 [1280/2870 (43%)]\tLoss: 1.158260\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 83 [2560/2870 (87%)]\tLoss: 1.151826\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1576/2870 (55%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 416/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.81      0.67      0.74       187\n",
      "   happiness       0.30      0.45      0.36        91\n",
      "     neutral       0.55      0.86      0.67       174\n",
      "     sadness       0.65      0.37      0.47       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.58      0.59      0.56       718\n",
      "weighted avg       0.62      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 84 [0/2870 (0%)]\tLoss: 1.141413\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 84 [1280/2870 (43%)]\tLoss: 1.163027\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 84 [2560/2870 (87%)]\tLoss: 1.199268\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1688/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 420/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.79      0.76       187\n",
      "   happiness       0.34      0.46      0.39        91\n",
      "     neutral       0.58      0.82      0.68       174\n",
      "     sadness       0.61      0.33      0.43       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.60      0.56       718\n",
      "weighted avg       0.60      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 85 [0/2870 (0%)]\tLoss: 1.121144\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 85 [1280/2870 (43%)]\tLoss: 1.099756\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 85 [2560/2870 (87%)]\tLoss: 1.110625\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1672/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 427/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.85      0.72       187\n",
      "   happiness       0.45      0.41      0.43        91\n",
      "     neutral       0.64      0.71      0.67       174\n",
      "     sadness       0.56      0.41      0.47       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.57      0.59      0.57       718\n",
      "weighted avg       0.58      0.59      0.58       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 86 [0/2870 (0%)]\tLoss: 1.172385\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 86 [1280/2870 (43%)]\tLoss: 1.109588\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 86 [2560/2870 (87%)]\tLoss: 1.179224\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1691/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 422/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.76      0.75       187\n",
      "   happiness       0.53      0.21      0.30        91\n",
      "     neutral       0.49      0.92      0.64       174\n",
      "     sadness       0.63      0.38      0.47       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.59      0.57      0.54       718\n",
      "weighted avg       0.61      0.59      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 87 [0/2870 (0%)]\tLoss: 1.103409\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 87 [1280/2870 (43%)]\tLoss: 1.121900\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 87 [2560/2870 (87%)]\tLoss: 1.159088\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1665/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 401/718 (56%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.84      0.74       187\n",
      "   happiness       0.29      0.38      0.33        91\n",
      "     neutral       0.56      0.84      0.67       174\n",
      "     sadness       0.61      0.24      0.34       266\n",
      "\n",
      "    accuracy                           0.56       718\n",
      "   macro avg       0.53      0.58      0.52       718\n",
      "weighted avg       0.57      0.56      0.53       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 88 [0/2870 (0%)]\tLoss: 1.057158\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 88 [1280/2870 (43%)]\tLoss: 1.156309\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 88 [2560/2870 (87%)]\tLoss: 1.128351\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1715/2870 (60%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 392/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.83      0.66      0.73       187\n",
      "   happiness       0.24      0.52      0.33        91\n",
      "     neutral       0.61      0.76      0.68       174\n",
      "     sadness       0.56      0.34      0.42       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.56      0.57      0.54       718\n",
      "weighted avg       0.60      0.55      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 89 [0/2870 (0%)]\tLoss: 1.136236\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 89 [1280/2870 (43%)]\tLoss: 1.223485\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 89 [2560/2870 (87%)]\tLoss: 1.162690\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0093\n",
      "\n",
      "\n",
      "Train Accuracy: 1616/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 408/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.92      0.43      0.58       187\n",
      "   happiness       0.29      0.41      0.34        91\n",
      "     neutral       0.59      0.81      0.68       174\n",
      "     sadness       0.57      0.56      0.57       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.59      0.55      0.54       718\n",
      "weighted avg       0.63      0.57      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 90 [0/2870 (0%)]\tLoss: 1.084495\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 90 [1280/2870 (43%)]\tLoss: 1.129323\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 90 [2560/2870 (87%)]\tLoss: 1.154928\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0092\n",
      "\n",
      "\n",
      "Train Accuracy: 1681/2870 (59%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 394/718 (55%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.78      0.75       187\n",
      "   happiness       0.29      0.48      0.36        91\n",
      "     neutral       0.55      0.82      0.66       174\n",
      "     sadness       0.60      0.23      0.34       266\n",
      "\n",
      "    accuracy                           0.55       718\n",
      "   macro avg       0.54      0.58      0.53       718\n",
      "weighted avg       0.58      0.55      0.52       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 91 [0/2870 (0%)]\tLoss: 1.067125\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 91 [1280/2870 (43%)]\tLoss: 1.155956\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 91 [2560/2870 (87%)]\tLoss: 1.099191\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1747/2870 (61%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 413/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.74      0.78      0.76       187\n",
      "   happiness       0.32      0.47      0.38        91\n",
      "     neutral       0.55      0.86      0.67       174\n",
      "     sadness       0.66      0.28      0.39       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.57      0.60      0.55       718\n",
      "weighted avg       0.61      0.58      0.55       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 92 [0/2870 (0%)]\tLoss: 1.141973\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 92 [1280/2870 (43%)]\tLoss: 1.181944\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 92 [2560/2870 (87%)]\tLoss: 1.221180\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0090\n",
      "\n",
      "\n",
      "Train Accuracy: 1725/2870 (60%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 438/718 (61%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.75      0.72      0.73       187\n",
      "   happiness       0.37      0.42      0.39        91\n",
      "     neutral       0.61      0.77      0.68       174\n",
      "     sadness       0.61      0.50      0.55       266\n",
      "\n",
      "    accuracy                           0.61       718\n",
      "   macro avg       0.58      0.60      0.59       718\n",
      "weighted avg       0.62      0.61      0.61       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 93 [0/2870 (0%)]\tLoss: 1.113746\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 93 [1280/2870 (43%)]\tLoss: 1.180648\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 93 [2560/2870 (87%)]\tLoss: 1.112510\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1676/2870 (58%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 434/718 (60%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.71      0.82      0.76       187\n",
      "   happiness       0.41      0.37      0.39        91\n",
      "     neutral       0.70      0.59      0.64       174\n",
      "     sadness       0.53      0.55      0.54       266\n",
      "\n",
      "    accuracy                           0.60       718\n",
      "   macro avg       0.59      0.58      0.58       718\n",
      "weighted avg       0.60      0.60      0.60       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 94 [0/2870 (0%)]\tLoss: 1.099816\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 94 [1280/2870 (43%)]\tLoss: 1.224502\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 94 [2560/2870 (87%)]\tLoss: 1.160703\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0094\n",
      "\n",
      "\n",
      "Train Accuracy: 1594/2870 (56%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 408/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.83      0.76       187\n",
      "   happiness       0.32      0.46      0.37        91\n",
      "     neutral       0.67      0.64      0.65       174\n",
      "     sadness       0.51      0.37      0.43       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.55      0.58      0.55       718\n",
      "weighted avg       0.57      0.57      0.56       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 95 [0/2870 (0%)]\tLoss: 1.086073\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 95 [1280/2870 (43%)]\tLoss: 1.126105\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 95 [2560/2870 (87%)]\tLoss: 1.084334\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0090\n",
      "\n",
      "\n",
      "Train Accuracy: 1759/2870 (61%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 419/718 (58%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.80      0.75       187\n",
      "   happiness       0.34      0.46      0.39        91\n",
      "     neutral       0.61      0.74      0.67       174\n",
      "     sadness       0.58      0.37      0.45       266\n",
      "\n",
      "    accuracy                           0.58       718\n",
      "   macro avg       0.56      0.59      0.57       718\n",
      "weighted avg       0.59      0.58      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 96 [0/2870 (0%)]\tLoss: 1.056447\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 96 [1280/2870 (43%)]\tLoss: 1.088435\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 96 [2560/2870 (87%)]\tLoss: 1.081756\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0090\n",
      "\n",
      "\n",
      "Train Accuracy: 1776/2870 (62%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 429/718 (60%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.79      0.76       187\n",
      "   happiness       0.34      0.47      0.40        91\n",
      "     neutral       0.63      0.72      0.67       174\n",
      "     sadness       0.59      0.42      0.49       266\n",
      "\n",
      "    accuracy                           0.60       718\n",
      "   macro avg       0.57      0.60      0.58       718\n",
      "weighted avg       0.60      0.60      0.59       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 97 [0/2870 (0%)]\tLoss: 1.176816\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 97 [1280/2870 (43%)]\tLoss: 1.188067\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 97 [2560/2870 (87%)]\tLoss: 1.129957\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0089\n",
      "\n",
      "\n",
      "Train Accuracy: 1767/2870 (62%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 410/718 (57%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.77      0.76      0.77       187\n",
      "   happiness       0.29      0.49      0.36        91\n",
      "     neutral       0.61      0.72      0.66       174\n",
      "     sadness       0.57      0.36      0.44       266\n",
      "\n",
      "    accuracy                           0.57       718\n",
      "   macro avg       0.56      0.59      0.56       718\n",
      "weighted avg       0.60      0.57      0.57       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 98 [0/2870 (0%)]\tLoss: 1.154305\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 98 [1280/2870 (43%)]\tLoss: 1.061543\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 98 [2560/2870 (87%)]\tLoss: 1.063971\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0090\n",
      "\n",
      "\n",
      "Train Accuracy: 1732/2870 (60%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 443/718 (62%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.64      0.86      0.73       187\n",
      "   happiness       0.53      0.32      0.40        91\n",
      "     neutral       0.58      0.84      0.69       174\n",
      "     sadness       0.67      0.41      0.51       266\n",
      "\n",
      "    accuracy                           0.62       718\n",
      "   macro avg       0.60      0.60      0.58       718\n",
      "weighted avg       0.62      0.62      0.59       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 99 [0/2870 (0%)]\tLoss: 1.110548\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 99 [1280/2870 (43%)]\tLoss: 1.130672\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 99 [2560/2870 (87%)]\tLoss: 1.159943\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1742/2870 (61%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 458/718 (64%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.83      0.75       187\n",
      "   happiness       0.74      0.15      0.25        91\n",
      "     neutral       0.61      0.79      0.69       174\n",
      "     sadness       0.61      0.57      0.59       266\n",
      "\n",
      "    accuracy                           0.64       718\n",
      "   macro avg       0.66      0.59      0.57       718\n",
      "weighted avg       0.65      0.64      0.61       718\n",
      " \n",
      "\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 100 [0/2870 (0%)]\tLoss: 1.175270\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 100 [1280/2870 (43%)]\tLoss: 1.109886\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "torch.Size([128, 199])\n",
      "Train Epoch: 100 [2560/2870 (87%)]\tLoss: 1.090248\n",
      "\n",
      "torch.Size([128, 199])\n",
      "torch.Size([54, 199])\n",
      "\n",
      "Train set: Average loss: 0.0091\n",
      "\n",
      "\n",
      "Train Accuracy: 1722/2870 (60%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 423/718 (59%)\n",
      "\n",
      "\n",
      " Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.62      0.84      0.72       187\n",
      "   happiness       0.44      0.36      0.40        91\n",
      "     neutral       0.58      0.82      0.68       174\n",
      "     sadness       0.62      0.34      0.44       266\n",
      "\n",
      "    accuracy                           0.59       718\n",
      "   macro avg       0.57      0.59      0.56       718\n",
      "weighted avg       0.59      0.59      0.56       718\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "n_epoch = 101\n",
    "for epoch in range(1, n_epoch):\n",
    "#     exp_lr_scheduler.step(epoch)\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    \n",
    "    train_loss, train_acc = train(epoch, model)\n",
    "    \n",
    "    test_loss, test_acc = test(model)\n",
    "    \n",
    "#     plateau_scheduler.step(test_loss)\n",
    "    \n",
    "    history.append([train_loss, train_acc, test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history, columns=[\"train_loss\", \"train_acc\", \"test_loss\", \"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history_df[\"epoch\"] = [x for x in range(1, n_epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011017</td>\n",
       "      <td>33</td>\n",
       "      <td>0.011062</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010395</td>\n",
       "      <td>42</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010113</td>\n",
       "      <td>48</td>\n",
       "      <td>0.010275</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009979</td>\n",
       "      <td>47</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009883</td>\n",
       "      <td>51</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.008991</td>\n",
       "      <td>61</td>\n",
       "      <td>0.009468</td>\n",
       "      <td>59</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.008922</td>\n",
       "      <td>61</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>57</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.008988</td>\n",
       "      <td>60</td>\n",
       "      <td>0.009470</td>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.009052</td>\n",
       "      <td>60</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>63</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.009095</td>\n",
       "      <td>60</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>58</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  train_acc  test_loss  test_acc  epoch\n",
       "0     0.011017         33   0.011062        43      1\n",
       "1     0.010395         42   0.010450        47      2\n",
       "2     0.010113         48   0.010275        53      3\n",
       "3     0.009979         47   0.010114        56      4\n",
       "4     0.009883         51   0.010097        54      5\n",
       "..         ...        ...        ...       ...    ...\n",
       "95    0.008991         61   0.009468        59     96\n",
       "96    0.008922         61   0.009531        57     97\n",
       "97    0.008988         60   0.009470        61     98\n",
       "98    0.009052         60   0.009601        63     99\n",
       "99    0.009095         60   0.009510        58    100\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "sns.lineplot(x='epoch', y='train_loss', data=history_df, color='b')\n",
    "# plt.xticks(history_df.epoch)\n",
    "sns.lineplot(x='epoch', y='test_loss', data=history_df, color='g')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set()\n",
    "sns.lineplot(x='epoch', y='train_acc', data=history_df, color='b')\n",
    "# plt.xticks(history_df.epoch)\n",
    "sns.lineplot(x='epoch', y='test_acc', data=history_df, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
